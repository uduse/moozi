{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b8746ef3",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-24T00:01:30.643794Z",
     "start_time": "2021-05-24T00:01:30.631317Z"
    }
   },
   "outputs": [],
   "source": [
    "import random\n",
    "import copy\n",
    "from collections import namedtuple\n",
    "from dataclasses import dataclass\n",
    "import datetime\n",
    "import typing\n",
    "import functools\n",
    "from pprint import pprint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e76b0af0",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-24T00:01:34.078590Z",
     "start_time": "2021-05-24T00:01:30.645724Z"
    }
   },
   "outputs": [],
   "source": [
    "import jax\n",
    "import jax.numpy as jnp\n",
    "from jax import grad, value_and_grad, jit, vmap\n",
    "from jax.experimental import optimizers\n",
    "from jax.experimental import stax\n",
    "import optax\n",
    "import haiku as hk\n",
    "from jax.tree_util import tree_flatten\n",
    "\n",
    "import pyspiel\n",
    "import open_spiel\n",
    "import dm_env\n",
    "import acme\n",
    "import acme.wrappers\n",
    "from acme.agents import agent\n",
    "from acme.agents import replay\n",
    "# from acme import core\n",
    "# from acme import specs\n",
    "# from acme import types\n",
    "# from acme import wrappers\n",
    "from acme.jax.utils import prefetch\n",
    "from acme.environment_loops.open_spiel_environment_loop import OpenSpielEnvironmentLoop\n",
    "from acme.wrappers.open_spiel_wrapper import OpenSpielWrapper\n",
    "# import bsuite\n",
    "\n",
    "from tqdm.notebook import tqdm\n",
    "import numpy as np\n",
    "import trueskill"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1d092b21",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-24T00:01:54.584927Z",
     "start_time": "2021-05-24T00:01:54.580564Z"
    }
   },
   "outputs": [],
   "source": [
    "import moozi as mz\n",
    "# from moozi import Game, Action, ActionHistory, Player"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ddb79026",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-24T00:01:59.634296Z",
     "start_time": "2021-05-24T00:01:59.627134Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'moozi.nerual_network' from '/workspace/moozi/nerual_network.py'>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mz.nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "85e83ce9",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-23T23:49:26.423629Z",
     "start_time": "2021-05-23T23:49:23.211739Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/usr/lib/x86_64-linux-gnu/libcuda.so.450.51.06\n",
      "/usr/lib/x86_64-linux-gnu/libcuda.so\n",
      "/usr/lib/x86_64-linux-gnu/libcuda.so.1\n",
      "/usr/local/lib/python3.8/dist-packages/torch/lib/libcudart-80664282.so.10.2\n",
      "/usr/local/cuda-11.0/compat/libcuda.so\n",
      "/usr/local/cuda-11.0/compat/libcuda.so.1\n",
      "/usr/local/cuda-11.0/compat/libcuda.so.450.119.03\n",
      "/usr/local/cuda-11.0/targets/x86_64-linux/lib/libcudart.so.11.0\n",
      "/usr/local/cuda-11.0/targets/x86_64-linux/lib/libcudart.so.11.0.221\n",
      "/usr/local/cuda-11.0/targets/x86_64-linux/lib/libcudadevrt.a\n",
      "/usr/local/cuda-11.0/targets/x86_64-linux/lib/libcudart.so\n",
      "/usr/local/cuda-11.0/targets/x86_64-linux/lib/libcudart_static.a\n",
      "/usr/local/cuda-11.0/targets/x86_64-linux/lib/stubs/libcuda.so\n",
      "/usr/local/cuda-11.0/extras/Debugger/include/libcudacore.h\n",
      "/usr/local/cuda-11.0/extras/Debugger/lib64/libcudacore.a\n",
      "Sun May 23 23:49:24 2021       \n",
      "+-----------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 450.51.06    Driver Version: 450.51.06    CUDA Version: 11.0     |\n",
      "|-------------------------------+----------------------+----------------------+\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                               |                      |               MIG M. |\n",
      "|===============================+======================+======================|\n",
      "|   0  TITAN RTX           On   | 00000000:00:06.0 Off |                  N/A |\n",
      "| 41%   33C    P8    22W / 280W |    166MiB / 24220MiB |      0%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   1  TITAN RTX           On   | 00000000:00:07.0 Off |                  N/A |\n",
      "| 41%   36C    P8    34W / 280W |    166MiB / 24220MiB |      0%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "                                                                               \n",
      "+-----------------------------------------------------------------------------+\n",
      "| Processes:                                                                  |\n",
      "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
      "|        ID   ID                                                   Usage      |\n",
      "|=============================================================================|\n",
      "+-----------------------------------------------------------------------------+\n",
      "nvcc: NVIDIA (R) Cuda compiler driver\n",
      "Copyright (c) 2005-2020 NVIDIA Corporation\n",
      "Built on Wed_Jul_22_19:09:09_PDT_2020\n",
      "Cuda compilation tools, release 11.0, V11.0.221\n",
      "Build cuda_11.0_bu.TC445_37.28845127_0\n",
      "jax\t [GpuDevice(id=0, process_index=0), GpuDevice(id=1, process_index=0)]\n",
      "torch\tTITAN RTX\n"
     ]
    }
   ],
   "source": [
    "%run hardware_sanity_check.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5748afac",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-23T23:49:26.449980Z",
     "start_time": "2021-05-23T23:49:26.434093Z"
    }
   },
   "outputs": [],
   "source": [
    "class LossExtra(typing.NamedTuple):\n",
    "    metrics: typing.Dict[str, jnp.DeviceArray]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "09741877",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-23T23:49:26.461980Z",
     "start_time": "2021-05-23T23:49:26.452892Z"
    }
   },
   "outputs": [],
   "source": [
    "def loss_fn(network, params, batch):\n",
    "    inf_out = network.initial_inference(\n",
    "        params, batch.data.observation.observation)\n",
    "    # TODO: use TD error instead\n",
    "    loss_scalar = jnp.mean(jnp.square(inf_out.value - batch.data.reward))\n",
    "    extra = LossExtra({})\n",
    "    return loss_scalar, extra"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "39f72f8e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-23T23:49:26.480840Z",
     "start_time": "2021-05-23T23:49:26.465749Z"
    }
   },
   "outputs": [],
   "source": [
    "# https://github.com/deepmind/acme/blob/a6b4162701542ed08b0b911ffac7c69fcb1bb3c7/acme/agents/jax/dqn/learning_lib.py#L68\n",
    "class TrainingState(typing.NamedTuple):\n",
    "    params: typing.Any\n",
    "    opt_state: optax.OptState\n",
    "    steps: int\n",
    "    rng_key: jax.random.PRNGKey\n",
    "        \n",
    "class MyLearner(acme.Learner):\n",
    "    def __init__(\n",
    "        self,\n",
    "        network,\n",
    "        loss_fn,\n",
    "        optimizer,\n",
    "        data_iterator, \n",
    "        random_key\n",
    "    ):\n",
    "        self.network = network\n",
    "        self._loss = jax.jit(functools.partial(loss_fn, self.network))\n",
    "        \n",
    "        @jax.jit\n",
    "        def sgd_step(training_state, batch):\n",
    "            key, new_key = jax.random.split(training_state.rng_key)\n",
    "            (loss, extra), grads = jax.value_and_grad(self._loss, has_aux=True)(training_state.params, batch)\n",
    "            extra.metrics.update({'loss': loss})\n",
    "            updates, new_opt_state = optimizer.update(grads, training_state.opt_state)\n",
    "            new_params = optax.apply_updates(training_state.params, updates)\n",
    "            steps = training_state.steps + 1\n",
    "            new_training_state = TrainingState(new_params, new_opt_state, steps, new_key)\n",
    "            return new_training_state, extra\n",
    "        \n",
    "        self._sgd_step = sgd_step\n",
    "        self._data_iterator = prefetch(data_iterator)\n",
    "        \n",
    "        key_params, key_state = jax.random.split(random_key, 2)\n",
    "        params = self.network.init(key_params)\n",
    "        self._state = TrainingState(\n",
    "            params=params,\n",
    "            opt_state=optimizer.init(params),\n",
    "            steps=0,\n",
    "            rng_key=key_state\n",
    "        )\n",
    "        self._counter = acme.utils.counting.Counter()\n",
    "        self._logger = acme.utils.loggers.TerminalLogger(time_delta=1., print_fn=print)\n",
    "        \n",
    "    def step(self):\n",
    "        batch = next(self._data_iterator)\n",
    "        self._state, extra = self._sgd_step(self._state, batch)\n",
    "        result = self._counter.increment(steps=1)\n",
    "        result.update(extra.metrics)\n",
    "        self._logger.write(result)\n",
    "        \n",
    "    def get_variables(self, names):\n",
    "        return [self._state.params]\n",
    "    \n",
    "    def save(self):\n",
    "        return self._state\n",
    "    \n",
    "    def restore(self, state):\n",
    "        self._state = state\n",
    "        \n",
    "class DoNothingLearner(acme.Learner):\n",
    "    def __init__(self, *args, **kwargs):\n",
    "        pass\n",
    "    \n",
    "    def step(self):\n",
    "        pass\n",
    "#         batch = next(self._data_iterator)\n",
    "#         self._state, loss = self._sgd_step(self._state, batch)\n",
    "#         self._logger.write(loss)\n",
    "        \n",
    "    def get_variables(self, names):\n",
    "        pass\n",
    "#         return [self._state.params]\n",
    "    \n",
    "    def save(self):\n",
    "        pass\n",
    "#         return self._state\n",
    "    \n",
    "    def restore(self, state):\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "26155ff5",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-23T23:49:26.495982Z",
     "start_time": "2021-05-23T23:49:26.483108Z"
    }
   },
   "outputs": [],
   "source": [
    "class MyAgentConfig(typing.NamedTuple):\n",
    "    batch_size: int = 32\n",
    "    learning_rate: float = 1e-3\n",
    "    min_observation: int = 0\n",
    "    observations_per_step: float = 1\n",
    "\n",
    "class MyAgent(agent.Agent):\n",
    "    def __init__(self, env_spec, config, network):\n",
    "        reverb_replay = replay.make_reverb_prioritized_nstep_replay(\n",
    "            env_spec, batch_size=config.batch_size,\n",
    "            n_step=3\n",
    "        )\n",
    "        # a must-have line?\n",
    "        self._server = reverb_replay.server\n",
    "        optimizer = optax.adam(config.learning_rate)\n",
    "        actor = RandomActor(reverb_replay.adder)\n",
    "        learner = MyLearner(\n",
    "            network=network,\n",
    "            loss_fn=loss_fn,\n",
    "            optimizer=optimizer,\n",
    "            data_iterator=reverb_replay.data_iterator, \n",
    "            random_key=jax.random.PRNGKey(0)\n",
    "        )\n",
    "        super().__init__(\n",
    "            actor=actor,\n",
    "            learner=learner,\n",
    "            min_observations=config.min_observation,\n",
    "            observations_per_step=config.observations_per_step\n",
    "        )\n",
    "        \n",
    "class RandomAgent(agent.Agent):\n",
    "    def __init__(self, env_spec, config, network):\n",
    "        reverb_replay = replay.make_reverb_prioritized_nstep_replay(\n",
    "            env_spec, batch_size=config.batch_size\n",
    "        )\n",
    "        \n",
    "        self._server = reverb_replay.server\n",
    "\n",
    "        optimizer = optax.adam(config.learning_rate)\n",
    "        actor = RandomActor(reverb_replay.adder)\n",
    "        learner = DoNothingLearner()\n",
    "        super().__init__(\n",
    "            actor=actor,\n",
    "            learner=learner,\n",
    "            min_observations=config.min_observation,\n",
    "            observations_per_step=config.observations_per_step\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6ac9a549",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-23T23:49:26.515474Z",
     "start_time": "2021-05-23T23:49:26.498584Z"
    }
   },
   "outputs": [],
   "source": [
    "# OpenSpiel environment, not using it for now since not supported by the latest relased Acme\n",
    "raw_env = open_spiel.python.rl_environment.Environment('catch(columns=8,rows=4)')\n",
    "env = acme.wrappers.open_spiel_wrapper.OpenSpielWrapper(raw_env)\n",
    "env = acme.wrappers.SinglePrecisionWrapper(env)\n",
    "env_spec = acme.specs.make_environment_spec(env)\n",
    "dim_action = env_spec.actions.num_values\n",
    "dim_image = env_spec.observations.observation.shape\n",
    "dim_repr = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "27bb116e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-23T23:50:01.213702Z",
     "start_time": "2021-05-23T23:50:01.208253Z"
    }
   },
   "outputs": [],
   "source": [
    "nn_spec = mz.nn.NeuralNetworkSpec(\n",
    "    dim_image=dim_image,\n",
    "    dim_repr=dim_repr,\n",
    "    dim_action=dim_action\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e1e671dd",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-23T23:50:01.980193Z",
     "start_time": "2021-05-23T23:50:01.975752Z"
    }
   },
   "outputs": [],
   "source": [
    "network = mz.nn.get_network(nn_spec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7479dd25",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-23T23:50:10.189791Z",
     "start_time": "2021-05-23T23:50:02.672514Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "my_agent = MyAgent(env_spec, MyAgentConfig(), network)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "0bfd55d2",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-23T23:50:12.278007Z",
     "start_time": "2021-05-23T23:50:12.271707Z"
    }
   },
   "outputs": [],
   "source": [
    "loop = OpenSpielEnvironmentLoop(environment=env, actors=[my_agent])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "13e56879",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-23T23:50:18.779496Z",
     "start_time": "2021-05-23T23:50:13.838006Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss = 0.00024332775501534343 | Steps = 1\n",
      "Loss = 0.32159119844436646 | Steps = 106\n",
      "Loss = 0.2494727522134781 | Steps = 222\n"
     ]
    }
   ],
   "source": [
    "loop.run(num_episodes=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "4f785e3f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-23T23:02:12.245556Z",
     "start_time": "2021-05-23T23:02:12.238683Z"
    }
   },
   "outputs": [],
   "source": [
    "sample = next(my_agent._learner._data_iterator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "ea7508d8",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-23T23:03:01.738438Z",
     "start_time": "2021-05-23T23:03:01.733649Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "d = sample.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "ee0af278",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-23T23:05:47.939439Z",
     "start_time": "2021-05-23T23:05:47.930924Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.,  0., -1.,  1.,  0., -1.,  0.,  0.,  0.,  0., -1.,  0., -1.,\n",
       "       -1., -1., -1., -1., -1.,  0., -1.,  0., -1., -1., -1.,  0., -1.,\n",
       "       -1.,  0., -1., -1., -1., -1.], dtype=float32)"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d.reward"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f1a869e4",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-23T06:49:38.487725Z",
     "start_time": "2021-05-23T06:49:37.268393Z"
    }
   },
   "outputs": [],
   "source": [
    "config = MyAgentConfig()\n",
    "reverb_replay = replay.make_reverb_prioritized_nstep_replay(\n",
    "    env_spec, batch_size=config.batch_size\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce670740",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2021-05-23T06:03:01.528Z"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8e9555e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
